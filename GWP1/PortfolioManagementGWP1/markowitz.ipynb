{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import visualisation\n",
    "import numpy as np\n",
    "import LinearRegression\n",
    "from visualisation import plot_kernel_density, plot_multiline_chart\n",
    "importlib.reload(visualisation)\n",
    "importlib.reload(LinearRegression)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from utilities import TimeSeries\n",
    "import polars as pl \n",
    "SHIT_COINS = ['DOGE-USD','SHIB-USD']\n",
    "DECENT_COINS = ['BTC-USD','ADA-USD']\n",
    "STABLE_COINS = ['USDT-USD']\n",
    "\n",
    "TICKERS = SHIT_COINS + DECENT_COINS + STABLE_COINS\n",
    "def get_market_data (ticker):\n",
    "    ticker = TimeSeries(ticker, \"2022-01-01\").construct_returns()\n",
    "    return pl.DataFrame(ticker.data).with_columns([pl.col(\"Date\").cast(pl.Date)])\n",
    "\n",
    "def get_return_vector (ticker_df):\n",
    "    return ticker_df.select(\"Returns\").drop_nulls().to_numpy().flatten()\n",
    "\n",
    "# return_vectors = [(get_return_vector(get_market_data(ticker)), ticker) for ticker in TICKERS]\n",
    "return_vectors = [get_market_data(ticker).write_csv(f\"C:/git/WQU/PortfolioManagement/{ticker}.csv\") for ticker in TICKERS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernel_density([return_vectors[2],return_vectors[3]],labels=True, title=\"KDE of Decent Coin Returns\", x_label=\"Returns\", y_label=\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernel_density([return_vectors[0],return_vectors[1]],labels=True, title=\"KDE of Shitcoin Returns\", x_label=\"Returns\", y_label=\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernel_density([return_vectors[4]],labels=True, title=\"KDE of Stablecoin Returns\", x_label=\"Returns\", y_label=\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_portfolio_weights(size, number_of_assets):\n",
    "    shape = [size, number_of_assets]\n",
    "    random_tensor = torch.rand(shape) * 0.5\n",
    "    return random_tensor / torch.sum(random_tensor, dim=1, keepdim=True)\n",
    "\n",
    "def get_covariance_matrix(data):\n",
    "    mean = torch.mean(data, dim=0)\n",
    "    centered_data = data - mean\n",
    "    cov_matrix = torch.matmul(centered_data.t(), centered_data) / data.shape[0]\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "def create_tensors (device, asset_returns):\n",
    "    if device == torch.device('cuda'):\n",
    "        # print(\"USING GPU\")\n",
    "        # print(\"Can use a larger number of allocations\")\n",
    "        number_of_random_allocations = 50000\n",
    "    else:\n",
    "        # print(\"USING CPU\")\n",
    "        # print(\"Keep number of allocations below 10000\")\n",
    "        number_of_random_allocations = 20000\n",
    "    asset_returns =  asset_returns.T.to(device)\n",
    "    allocation = generate_random_portfolio_weights(number_of_random_allocations, 5).T.to(device)\n",
    "    return asset_returns, allocation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_tensors = [torch.Tensor(r[0]) for r in return_vectors]\n",
    "asset_returns_stacked = torch.stack((return_tensors))\n",
    "asset_returns, allocation = create_tensors(gpu, asset_returns=asset_returns_stacked)\n",
    "covariance_matrix_asset_return = get_covariance_matrix(asset_returns)\n",
    "portfolio_variance = torch.diag(allocation.T @ covariance_matrix_asset_return @ allocation)\n",
    "average_returns = torch.mean(asset_returns, dim=0).reshape(1, -1)\n",
    "mean_vector = average_returns @ allocation\n",
    "stddev_vector = torch.sqrt(portfolio_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualisation import plot_multiscatter\n",
    "plot_multiscatter([(stddev_vector.cpu().numpy(),mean_vector.cpu().numpy() ,\"Risk vs Return\")], title=\"Random Asset Allocations\",x_label=\"Risk\", y_label=\"Return\", markersize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy import optimize\n",
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers\n",
    "\n",
    "n = len(asset_returns.T)\n",
    "returns = np.asmatrix(asset_returns.T.cpu().numpy().astype(np.double))    \n",
    "N = 100000\n",
    "mus = [100**(5.0 * t/N - 1.0) for t in range(N)]\n",
    "S = opt.matrix(covariance_matrix_asset_return.cpu().numpy().astype(np.double))\n",
    "pbar = opt.matrix(np.mean(returns, axis=1))\n",
    "\n",
    "\n",
    "non_negativity_constraint_matrix = -opt.matrix(np.eye(n))  \n",
    "zero_vector = opt.matrix(0.0, (n ,1))\n",
    "full_investment_constraint_matrix = opt.matrix(1.0, (1, n))\n",
    "ones_vector = opt.matrix(1.0)\n",
    "\n",
    "# Note: Please do not run the quadratic programming solution in this notebook as it may take a significant amount of time to execute. The optimal portfolio has already been calculated and saved as a pickle file.\n",
    "\n",
    "# portfolios = [solvers.qp(mu*S, -pbar, non_negativity_constraint_matrix, zero_vector, full_investment_constraint_matrix, ones_vector)['x'] for mu in mus]\n",
    "\n",
    "with open(\"optimal_portfolio.pkl\", 'rb') as handle:\n",
    "    portfolios = pickle.load(handle)\n",
    "returns = torch.Tensor([blas.dot(pbar, x) for x in portfolios])\n",
    "risks = torch.Tensor([np.sqrt(blas.dot(x, S*x)) for x in portfolios])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_portfolio_with_maximum_sharpe_ratio (risks, returns):\n",
    "    sharpe = returns / risks\n",
    "    index = torch.argmax(sharpe)\n",
    "    return risks[index].item(), returns[index].item()\n",
    "\n",
    "best_portfolio_std, best_portfolio_mean = find_portfolio_with_maximum_sharpe_ratio(risks, returns)\n",
    "eqn_of_the_line = lambda x : ( (best_portfolio_mean-risk_free_rate) / best_portfolio_std ) * x + risk_free_rate  \n",
    "cml_domain = np.linspace(0,0.06,10000)\n",
    "cml_range = np.array([eqn_of_the_line(i) for i in cml_domain])\n",
    "from visualisation import plot_multiscatter\n",
    "\n",
    "plot_multiscatter(\n",
    "    [(stddev_vector.cpu().numpy(), mean_vector.cpu().numpy(), \"Random Portfolio\",'o',5,0.5),\n",
    "     (risks, returns, \"Efficient Frontier\", '_'),\n",
    "     (cml_domain, cml_range, \"Capital Market Line\", \"_\", 5, 0.5),\n",
    "     (best_portfolio_std, best_portfolio_mean, \"Optimal Portfolio\", 'D', 50, 1)],\n",
    "    title=\"Optimal Portfolio\",\n",
    "    x_label=\"Risk\",\n",
    "    y_label=\"Return\",\n",
    "    markersize=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   36.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 02 May 2024</td> <th>  Prob (F-statistic):</th> <td>1.67e-22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:05:28</td>     <th>  Log-Likelihood:    </th> <td>  974.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1046</td>      <th>  AIC:               </th> <td>  -1940.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1042</td>      <th>  BIC:               </th> <td>  -1920.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0012</td> <td>    0.003</td> <td>   -0.422</td> <td> 0.673</td> <td>   -0.007</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0322</td> <td>    0.004</td> <td>    8.366</td> <td> 0.000</td> <td>    0.025</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0041</td> <td>    0.002</td> <td>    1.686</td> <td> 0.092</td> <td>   -0.001</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0083</td> <td>    0.002</td> <td>    4.001</td> <td> 0.000</td> <td>    0.004</td> <td>    0.012</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1173.597</td> <th>  Durbin-Watson:     </th>  <td>   1.782</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>166310.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 5.253</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>63.873</td>  <th>  Cond. No.          </th>  <td>    1.95</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.095   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.093   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     36.62   \\\\\n",
       "\\textbf{Date:}             & Thu, 02 May 2024 & \\textbf{  Prob (F-statistic):} &  1.67e-22   \\\\\n",
       "\\textbf{Time:}             &     22:05:28     & \\textbf{  Log-Likelihood:    } &    974.11   \\\\\n",
       "\\textbf{No. Observations:} &        1046      & \\textbf{  AIC:               } &    -1940.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1042      & \\textbf{  BIC:               } &    -1920.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -0.0012  &        0.003     &    -0.422  &         0.673        &       -0.007    &        0.005     \\\\\n",
       "\\textbf{x1}    &       0.0322  &        0.004     &     8.366  &         0.000        &        0.025    &        0.040     \\\\\n",
       "\\textbf{x2}    &       0.0041  &        0.002     &     1.686  &         0.092        &       -0.001    &        0.009     \\\\\n",
       "\\textbf{x3}    &       0.0083  &        0.002     &     4.001  &         0.000        &        0.004    &        0.012     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1173.597 & \\textbf{  Durbin-Watson:     } &     1.782   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 166310.298  \\\\\n",
       "\\textbf{Skew:}          &   5.253  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &  63.873  & \\textbf{  Cond. No.          } &      1.95   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.095\n",
       "Model:                            OLS   Adj. R-squared:                  0.093\n",
       "Method:                 Least Squares   F-statistic:                     36.62\n",
       "Date:                Thu, 02 May 2024   Prob (F-statistic):           1.67e-22\n",
       "Time:                        22:05:28   Log-Likelihood:                 974.11\n",
       "No. Observations:                1046   AIC:                            -1940.\n",
       "Df Residuals:                    1042   BIC:                            -1920.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0012      0.003     -0.422      0.673      -0.007       0.005\n",
       "x1             0.0322      0.004      8.366      0.000       0.025       0.040\n",
       "x2             0.0041      0.002      1.686      0.092      -0.001       0.009\n",
       "x3             0.0083      0.002      4.001      0.000       0.004       0.012\n",
       "==============================================================================\n",
       "Omnibus:                     1173.597   Durbin-Watson:                   1.782\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           166310.298\n",
       "Skew:                           5.253   Prob(JB):                         0.00\n",
       "Kurtosis:                      63.873   Cond. No.                         1.95\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import polars as pl\n",
    "import datetime\n",
    "df = pl.read_csv(\"FF3.CSV\").with_columns(pl.col(\"\").cast(pl.Utf8).str.to_date(format=\"%Y%m%d\").alias(\"Date\")).filter(pl.col(\"Date\").is_in(pl.Series(gme['Date']).cast(pl.Date))).drop(\"\").join(gme.select(pl.col(\"Date\"), pl.col(\"Returns\")), on=\"Date\").with_columns((pl.col(\"Returns\")-pl.col(\"RF\")).alias(\"ExcessReturns\")).drop_nulls()\n",
    "x=df.select(pl.col('SMB'), pl.col('HML'), pl.col('Mkt-RF')).to_numpy()\n",
    "y=df.select(pl.col('ExcessReturns')).to_numpy()\n",
    "model = sm.OLS(y, sm.add_constant(x))\n",
    "model.fit().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import polars as pl\n",
    "import importlib\n",
    "importlib.reload(LinearRegression)\n",
    "from LinearRegression import RegressionUtility, RegressionType\n",
    "regression = RegressionUtility(device='cuda', x=x, y=y, regression_type=RegressionType.Linear, epochs=50000, delta_to_early_stop=1e-20, learning_rate=0.01, variable_names=['SMB', 'HML', 'Mkt-RF'])\n",
    "regression.fit()\n",
    "print(regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualisation import plot_kernel_density\n",
    "res = plot_kernel_density([(regression.residuals.detach().cpu().numpy(), \"Residuals\")], title=\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(visualisation)\n",
    "from visualisation import plot_multiscatter\n",
    "plot = plot_multiscatter([(regression.y_pred_numpy, regression.residuals.detach().cpu().numpy(), \"Residuals vs Fitted\")], title=\"Residuals vs Fitted\", x_label=\"Fitted\", y_label=\"Residuals\", markersize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3//2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualisation import plot_multiscatter\n",
    "\n",
    "plot_multiscatter(\n",
    "    [(stddev_vector.cpu().numpy(), mean_vector.cpu().numpy(), \"Risk vs Return\"),\n",
    "     (risks, returns, \"Efficient Frontier\")],\n",
    "    title=\"Efficient Frontier\",\n",
    "    x_label=\"Risk\",\n",
    "    y_label=\"Return\",\n",
    "    markersize=5,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
